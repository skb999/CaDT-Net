{
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8146556,
          "sourceType": "datasetVersion",
          "datasetId": 4817492
        },
        {
          "sourceType": "datasetVersion",
          "sourceId": 8158384,
          "datasetId": 4826407
        }
      ],
      "dockerImageVersionId": 30683,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install \"tensorflow>=1.7.0\"\n",
        "!pip install tensorflow-addons\n",
        "!pip install tensorflow-hub\n",
        "\n",
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vq5qLS4d2LmQ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, utils\n",
        "import tensorflow_addons as tfa"
      ],
      "metadata": {
        "id": "vmaszhvR2LmY",
        "scrolled": true,
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(f\"tensorflow version: {tf.__version__}\")\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Ht481_PZ2LmZ",
        "outputId": "0607415e-0c8b-41b5-dd54-556994fe3d79",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version: 2.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import math\n",
        "import os\n",
        "import statistics\n",
        "from keras import layers\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import image\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Input, Dense, DepthwiseConv2D,AveragePooling2D, Concatenate, Dropout, Permute,Reshape,Lambda,Activation, Add,Multiply, MaxPooling2D, Conv2D, Flatten, BatchNormalization, GlobalAveragePooling2D,LayerNormalization\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16,ConvNeXtTiny,ResNet50, MobileNet, Xception, EfficientNetB0 , DenseNet169, DenseNet201, DenseNet121, InceptionV3, NASNetLarge, InceptionResNetV2, NASNetMobile\n",
        "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
        "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import gc\n",
        "import itertools\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "from functools import partial\n",
        "from collections import Counter\n",
        "from statistics import mean\n",
        "\n",
        "from keras.models import load_model\n",
        "#from keras.models import Sequential\n",
        "from matplotlib import pyplot as plt\n",
        "import h5py\n",
        "import cv2\n",
        "import glob\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "o91Tp0x_sHTl",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.version.VERSION, tf.config.list_physical_devices()"
      ],
      "metadata": {
        "id": "N-4YPF2w26ll",
        "outputId": "4265e605-ea25-4659-8297-34ae03267c8a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('2.15.0',\n",
              " [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
              "  PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = '/content/drive/MyDrive/Breast Cancer Project/IW/40/A'\n",
        "F = '/content/drive/MyDrive/Breast Cancer Project/IW/40/F'\n",
        "PT ='/content/drive/MyDrive/Breast Cancer Project/IW/40/PT'\n",
        "TA ='/content/drive/MyDrive/Breast Cancer Project/IW/40/TA'\n",
        "DC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/DC'\n",
        "LC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/LC'\n",
        "MC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/MC'\n",
        "PC ='/content/drive/MyDrive/Breast Cancer Project/IW/40/PC'"
      ],
      "metadata": {
        "id": "4EWX3Gd8r32a",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dirlist=[A, F, PT, TA, DC, LC, MC, PC]\n",
        "classes=['A','F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "filepaths=[]\n",
        "labels=[]\n",
        "for i,j in zip(dirlist, classes):\n",
        "    filelist=os.listdir(i)\n",
        "    for f in filelist:\n",
        "        filepath=os.path.join (i,f)\n",
        "        filepaths.append(filepath)\n",
        "        labels.append(j)\n",
        "print ('filepaths: ', len(filepaths), '   labels: ', len(labels))"
      ],
      "metadata": {
        "id": "QNZkBeucr9Mh",
        "outputId": "3a1ee7c7-1cf5-4c5b-c76a-4397a155bb17",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "filepaths:  1995    labels:  1995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Files=pd.Series(filepaths, name='filepaths')\n",
        "Label=pd.Series(labels, name='labels')\n",
        "df=pd.concat([Files,Label], axis=1)\n",
        "df=pd.DataFrame(np.array(df).reshape(len(filepaths),2), columns = ['filepaths', 'labels'])\n",
        "df.head()"
      ],
      "metadata": {
        "id": "QVgOHhygsAlZ",
        "outputId": "6fb57624-c4f3-4800-90f4-eb9d1963f026",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           filepaths labels\n",
              "0  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "1  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "2  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "3  /content/drive/MyDrive/Breast Cancer Project/I...      A\n",
              "4  /content/drive/MyDrive/Breast Cancer Project/I...      A"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f130e7b2-9e23-4cf0-96b3-92842aaaac61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepaths</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Breast Cancer Project/I...</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f130e7b2-9e23-4cf0-96b3-92842aaaac61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f130e7b2-9e23-4cf0-96b3-92842aaaac61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f130e7b2-9e23-4cf0-96b3-92842aaaac61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff142a3d-02ce-430d-a776-502a2eca5c01\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff142a3d-02ce-430d-a776-502a2eca5c01')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff142a3d-02ce-430d-a776-502a2eca5c01 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1995,\n  \"fields\": [\n    {\n      \"column\": \"filepaths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1995,\n        \"samples\": [\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/40/DC/SOB_M_DC-14-11951-40-003.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/40/MC/SOB_M_MC-14-19979C-40-017.png\",\n          \"/content/drive/MyDrive/Breast Cancer Project/IW/40/PT/SOB_B_PT-14-21998AB-40-054.png\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"F\",\n          \"LC\",\n          \"A\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['labels'].value_counts())"
      ],
      "metadata": {
        "id": "1uQkt3MTsD_o",
        "outputId": "7ea7b854-2719-42ff-86ea-ced06db33b1b",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels\n",
            "DC    864\n",
            "F     253\n",
            "MC    205\n",
            "LC    156\n",
            "TA    149\n",
            "PC    145\n",
            "A     114\n",
            "PT    109\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, train_size=0.70)\n",
        "#train_new, valid = train_test_split(train, train_size=0.90, random_state=0)\n",
        "\n",
        "print(f\"train set shape: {train.shape}\")\n",
        "print(f\"test set shape: {test.shape}\")\n",
        "print(f\"validation set shape: {test.shape}\")"
      ],
      "metadata": {
        "id": "pfI-lh99sGr7",
        "outputId": "21a891e5-851f-405f-c4f9-a503d1787471",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set shape: (1396, 2)\n",
            "test set shape: (599, 2)\n",
            "validation set shape: (599, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,\n",
        "                                   shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True, vertical_flip =True)\n",
        "test_datagen = ImageDataGenerator(rescale = 1.0/255.)"
      ],
      "metadata": {
        "id": "BF_mNPBOsQPL",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define tand get the number os devices.\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(dataframe=train,\n",
        "                                              x_col = 'filepaths', y_col ='labels',\n",
        "                                              target_size = (224,224), batch_size = 4 * strategy.num_replicas_in_sync,\n",
        "                                              class_mode = 'categorical', shuffle = True)\n",
        "\n",
        "val_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4 * strategy.num_replicas_in_sync, shuffle = False)\n",
        "\n",
        "\n",
        "test_gen = test_datagen.flow_from_dataframe(test,\n",
        "                                            target_size = (224,224),   x_col = 'filepaths', y_col ='labels',\n",
        "                                             class_mode = 'categorical',\n",
        "                                            batch_size = 4, shuffle = False)"
      ],
      "metadata": {
        "id": "4Gl5R4EJsRbN",
        "outputId": "010d26dc-134d-4495-dc68-e093a916d66c",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DEVICES AVAILABLE: 1\n",
            "Found 1396 validated image filenames belonging to 8 classes.\n",
            "Found 599 validated image filenames belonging to 8 classes.\n",
            "Found 599 validated image filenames belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "    smoothed_points = []\n",
        "    for point in points:\n",
        "        if smoothed_points:\n",
        "            previous = smoothed_points[-1]\n",
        "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "        else:\n",
        "            smoothed_points.append(point)\n",
        "    return smoothed_points\n",
        "\n",
        "def plotmodel(history,name):\n",
        "\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.plot(epochs,smooth_curve(acc))\n",
        "    plt.plot(epochs,smooth_curve(val_acc))\n",
        "    plt.ylabel('acc')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_acc', 'val_acc'], loc='upper left')\n",
        "    #plt.savefig('acc_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "    plt.figure(2)\n",
        "    plt.plot(epochs,smooth_curve(loss))\n",
        "    plt.plot(epochs,smooth_curve(val_loss))\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train_loss', 'val_loss'], loc='upper right')\n",
        "   # plt.savefig('loss_'+name+'_'+mag+'_'+fold+'.png')\n",
        "\n",
        "def label_smooth(y_true, y_pred):\n",
        "    y_true=((1-0.1)*y_true+0.05)\n",
        "    return K.categorical_crossentropy(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "CJBdug_F2Lmc",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                        normalize=False,\n",
        "                        title='Confusion matrix',\n",
        "                        cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 3.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"green\" if cm[i, j] > thresh else \"red\", fontdict={'fontsize':'x-large'})\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "LeIVRsgY2Lmc",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DefConv_full(input, filters, kernel_size, strides=1):\n",
        "    \"\"\"\n",
        "    Using DefConv_reduced to implement full DC layer.\n",
        "    \"\"\"\n",
        "    offsets = layers.Conv2D(filters=2 * kernel_size ** 2,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same',\n",
        "                            kernel_initializer='random_normal'\n",
        "                            )(input)\n",
        "    X = DefConvLayer_red(filters=filters,\n",
        "                         kernel_size=kernel_size,\n",
        "                         strides=strides\n",
        "                         )(input, offsets)\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "class DefConvLayer_red(Layer):\n",
        "\n",
        "    def __init__(self, filters,strides, kernel_size=3, **kwargs):\n",
        "        assert type(kernel_size) == int, \"expect kernel_size to be of type 'int'\"\n",
        "        assert type(strides) == int, \"expect strides to be of type int\"\n",
        "        self.N = kernel_size ** 2\n",
        "        self.filters = filters\n",
        "        self.strides = strides\n",
        "\n",
        "        super(DefConvLayer_red, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], self.N, self.filters),\n",
        "                                 # Wdc is of shape [n_C=input_channels, lxl=N, filters=output_channels]\n",
        "                                 initializer='RandomNormal',\n",
        "                                 dtype='float32',\n",
        "                                 trainable=True)\n",
        "\n",
        "    def call(self, input, offsets):\n",
        "        # input of shape: (m=batch_size, n_H, n_W, n_C)\n",
        "        # offsets of shape: (m, n_H, n_W, 2*N)\n",
        "        # m, n_H, n_W, n_C = input.shape\n",
        "        # offsets = super(DefConvLayer, self).call(input) # Conv2D to learn offsets (m, n_H, n_W, 2*N)\n",
        "\n",
        "        input_offsets = self.BLIN(input, offsets)  # (m, n_H, n_W, n_C, N)\n",
        "        # BLIN returns N interpolated values of input at the offsets, for each spatial pixel\n",
        "        # replicate the offset input to each of the output channels\n",
        "        input_offsets = tf.expand_dims(input_offsets, axis=-1)\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, 1, self.filters])  # (m, n_H, n_W, n_C, N, filters)\n",
        "\n",
        "        new_shape = (1, 1, 1,) + self.W.shape\n",
        "        W = tf.reshape(self.W, shape=new_shape)  # (1, 1, 1, n_C, N, filters) to be broadcastable to input_offsets\n",
        "\n",
        "        output = tf.multiply(input_offsets, W)  # (m, n_H, n_W, n_C, N, filters)\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, n_C, filters) reduce along each channel kernel\n",
        "        output = tf.math.reduce_sum(output, axis=-2)  # (m, n_H, n_W, filters) reduce along input channels\n",
        "        return output\n",
        "\n",
        "    @tf.function\n",
        "    def BLIN(self, input, offsets_in):  # Bi-Linear Interpolation of input feature map values at offset locations\n",
        "        \"\"\"\n",
        "        'input' shape: (m, n_Hi, n_Wi, n_C)\n",
        "        'offsets_in' shape: (m, n_Ho, n_Wo, 2*N)\n",
        "        'offsets_in' is the output of the Conv2D layer step aimed at learning the offsets,\n",
        "                     possibly smaller spatial size than input's, if strides>1\n",
        "        \"\"\"\n",
        "        offsets = offsets_in\n",
        "        m    = tf.shape(input)[0]\n",
        "        n_Hi = tf.shape(input)[1]\n",
        "        n_Wi = tf.shape(input)[2]\n",
        "        n_C  = tf.shape(input)[3]\n",
        "\n",
        "        n_Ho = tf.shape(offsets)[1] # also the output spatial shape\n",
        "        n_Wo = tf.shape(offsets)[2]\n",
        "        N    = tf.shape(offsets)[3] // 2\n",
        "\n",
        "        # expand the input into (m, n_Hi, n_Wi, n_C, N). this will also be the output shape of this function\n",
        "        input_offsets = tf.expand_dims(input, axis=-1) # (m, n_Hi, n_Wi, n_C, N, 1)\n",
        "        # replicate N times, to be compatible with the kernel operation later\n",
        "        input_offsets = tf.tile(input_offsets, [1, 1, 1, 1, N])  # (m, n_Hi, n_Wi, n_C, N)\n",
        "\n",
        "        # the offset metrices will be replicated n_C times: same (spatial) offsets for each of the input *channels*.\n",
        "        offsets = tf.reshape(offsets, (m, n_Ho, n_Wo, 1, N, 2))  # (m, n_Ho, n_Wo, 1, N, 2) add a \"channel\" axis\n",
        "        offsets = tf.tile(offsets, [1, 1, 1, n_C, 1, 1])  # (m, n_Ho, n_Wo, n_C, N, 2) replicate for each of the input channels\n",
        "\n",
        "        # construct a full index grid to be applied onto \"input_offsets\" of size (m, n_H, n_W, n_C, N)\n",
        "        (grid_m, grid_i, grid_j, grid_c, grid_N) = tf.meshgrid(tf.range(m), tf.range(n_Hi),\n",
        "                                                               tf.range(n_Wi), tf.range(n_C), tf.range(N),\n",
        "                                                               indexing='ij')  # (m, n_Hi, n_Wi, n_C, N) a list of 5 metrices with index-like values\n",
        "\n",
        "        # adjust indices to 'strides' down-sample, and\n",
        "        # unroll indices to fit into tf.gather_nd later. (unroll offsets also)\n",
        "        ur_grid_m = tf.reshape(grid_m[:, ::self.strides, ::self.strides, :, :], [-1])  # (m*n_Ho*n_Wo*n_C*N, 1); integers\n",
        "        ur_grid_i = tf.reshape(grid_i[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_j = tf.reshape(grid_j[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_c = tf.reshape(grid_c[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_grid_N = tf.reshape(grid_N[:, ::self.strides, ::self.strides, :, :], [-1])\n",
        "        ur_offsets = tf.reshape(offsets, (-1, 2))  # (m*n_Ho*n_Wo*n_C*N, 2) both i, j\n",
        "\n",
        "        # spatial indices will be adjusted using 'offsets'\n",
        "        coords_i = tf.cast(ur_grid_i, dtype='float32') + ur_offsets[..., 0]\n",
        "        coords_j = tf.cast(ur_grid_j, dtype='float32') + ur_offsets[..., 1]\n",
        "\n",
        "        # Need to think further on how to handle edges,\n",
        "        # perhaps assume outside of index values can be zeros instead of hard-clipping.\n",
        "        coords_i = tf.clip_by_value(coords_i, 0, tf.cast(n_Hi, dtype='float32')-1)\n",
        "        coords_j = tf.clip_by_value(coords_j, 0, tf.cast(n_Wi, dtype='float32')-1)\n",
        "        coords_2d = tf.stack([coords_i, coords_j], axis=-1)  # (m*n_Ho*n_Wo*n_C*N, 2); float32\n",
        "\n",
        "        # generate top and bottom, left and right, nearest \"real\" indices\n",
        "        # assuming coords represents (p,q) values where i<=p<=i+1, and j<=q<=j+1:\n",
        "        # shape: (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "        # note the coordinates themselves (values in coords) are [i,j] within [0:n_Hi-1, 0:n_Wi] range\n",
        "        coords_lt = tf.cast(tf.math.floor(coords_2d), dtype='int32')  # nearest (i,j)\n",
        "        coords_rb = tf.cast(tf.math.ceil(coords_2d), dtype='int32')  # nearest (i+1, j+1)\n",
        "\n",
        "        coords_lb = tf.stack((coords_rb[..., 0], coords_lt[..., 1]), axis=-1)  # nearest (i+1, j)\n",
        "        coords_rt = tf.stack((coords_lt[..., 0], coords_rb[..., 1]), axis=-1)  # nearest (i, j+1)\n",
        "\n",
        "        # use the replicated input tensor \"input_offsets\" which holds the input values, to get these values at the specific locations:\n",
        "        # these type of Tensors doesn't allow for conversion into numpy-like arrays. to use tf.gather_nd, need to unroll indices\n",
        "        # unroll all grid tensors to be used with tf.gather_nd()\n",
        "\n",
        "        indices_lt = tf.stack([ur_grid_m, coords_lt[..., 0], coords_lt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rb = tf.stack([ur_grid_m, coords_rb[..., 0], coords_rb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_lb = tf.stack([ur_grid_m, coords_lb[..., 0], coords_lb[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "        indices_rt = tf.stack([ur_grid_m, coords_rt[..., 0], coords_rt[..., 1], ur_grid_c, ur_grid_N], axis=-1)\n",
        "\n",
        "        vals_lt = tf.gather_nd(input_offsets, indices_lt)\n",
        "        vals_rb = tf.gather_nd(input_offsets, indices_rb)\n",
        "        vals_lb = tf.gather_nd(input_offsets, indices_lb)\n",
        "        vals_rt = tf.gather_nd(input_offsets, indices_rt)\n",
        "\n",
        "        # calculate the offset from the left-top (i,j) position\n",
        "        ur_coords_offset_lt = coords_2d - tf.cast(coords_lt, dtype='float32')  # (m*n_Ho*n_Wo*n_C*N, 2)\n",
        "\n",
        "        # first linear interpolation (m*n_H*n_W*n_C*N)\n",
        "        vals_t = vals_lt + (vals_rt - vals_lt) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), top\n",
        "        vals_b = vals_lb + (vals_rb - vals_lb) * ur_coords_offset_lt[..., 1]  # along the j axis (n_Wi), bottom\n",
        "\n",
        "        # second linear interpolation\n",
        "        input_offsets = vals_t + (vals_b - vals_t) * ur_coords_offset_lt[..., 0]  # along the i axis (n_Hi)\n",
        "\n",
        "        # reshape back to output shape\n",
        "        input_offsets = tf.reshape(input_offsets, (m, n_Ho, n_Wo, n_C, N))\n",
        "\n",
        "        return input_offsets"
      ],
      "metadata": {
        "id": "hwUptDC7WJHS",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "def train_model(model, train_gen, val_gen, test_gen, mag, image_size, save_name, lr1, lr2, Epochs1, Epochs2):\n",
        "    from keras.callbacks import ModelCheckpoint\n",
        "    from keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "    lr_decay = ReduceLROnPlateau(monitor='loss', factor=0.8, patience=3, verbose=1)\n",
        "    save_model = ModelCheckpoint('/content/drive/MyDrive/100+{epoch:02d}.h5',\n",
        "                                 monitor='val_accuracy',\n",
        "                                 period=5,\n",
        "                                 save_best_only=True)\n",
        "\n",
        "    # List of model names\n",
        "    model_names = ['40epoch+01.h5', '40epoch+06.h5', '40epoch+21.h5', '40epoch+26.h5', '40epoch+36.h5', '40epoch+81.h5']\n",
        "\n",
        "    # List to store loaded models\n",
        "    loaded_models = []\n",
        "\n",
        "    custom_objects = {\n",
        "        'DefConvLayer_red': DefConvLayer_red  # Assuming 'DefConvLayer_red' is a custom layer\n",
        "    }\n",
        "\n",
        "    # Load models in a loop\n",
        "    for model_name in model_names:\n",
        "        # Construct the full path to the model file\n",
        "        model_path = '/content/drive/MyDrive/Epochs/40/' + model_name\n",
        "\n",
        "        # Load the model and append it to the list\n",
        "        model = load_model(model_path, custom_objects=custom_objects)\n",
        "        loaded_models.append(model)\n",
        "\n",
        "        # Evaluate the loaded model\n",
        "        results = model.evaluate(test_gen)\n",
        "        print('Test loss and accuracy for model', model_name, ':', results)\n",
        "\n",
        "        # Make predictions\n",
        "        predictions = model.predict(test_gen)\n",
        "        rounded_pred = np.argmax(predictions, axis=-1)\n",
        "\n",
        "        # Generate confusion matrix\n",
        "        cm = confusion_matrix(y_true=test_gen.classes, y_pred=rounded_pred)\n",
        "        cm_plot_labels = ['A', 'F', 'PT', 'TA', 'DC', 'LC', 'MC', 'PC']\n",
        "        plot_confusion_matrix(cm=cm, classes=cm_plot_labels, title='Confusion Matrix for model ' + model_name)\n",
        "\n",
        "        # Print classification report\n",
        "        print('Classification report for model', model_name, ':')\n",
        "        print(classification_report(y_true=test_gen.classes, y_pred=rounded_pred, target_names=cm_plot_labels))\n",
        "\n",
        "    # Return something meaningful, e.g., history\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "mDj2Er1H2Lmf",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U git+https://github.com/leondgarse/keras_cv_attention_models"
      ],
      "metadata": {
        "id": "COIWAnOotVGZ",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def SSA(inputs,fltr):\n",
        "    shape=K.int_shape(inputs)\n",
        "    li=q=k=v=Conv2D(fltr,1,padding='same',activation='relu')(inputs)\n",
        "    print(\"Shape of Input of SSA\", inputs)\n",
        "    Qshape=K.int_shape(q)\n",
        "    Kshape= K.int_shape(k)\n",
        "    Vshape= K.int_shape(v)\n",
        "    a=Qshape[1]*Qshape[2]\n",
        "    q=Reshape((a,Qshape[3]))(q)\n",
        "    k=Reshape((a,Kshape[3]))(k)\n",
        "    k=Permute((2,1))(k)\n",
        "    qk=tf.matmul(q,k)\n",
        "    qk=Activation('softmax')(qk)\n",
        "    v=Reshape((a,Vshape[3]))(v)\n",
        "    qkv=tf.matmul(qk,v)\n",
        "    print(qkv.shape)\n",
        "    qkv=Reshape((Vshape[1],Vshape[2],Vshape[3]))(qkv)\n",
        "    qkv = Conv2D(shape[3], 1, strides=1, padding='same', activation='relu')(qkv)\n",
        "    print(\"Shape of Output of SSA\", qkv)\n",
        "    return qkv"
      ],
      "metadata": {
        "id": "gfdo3wQDgQWF",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "def CDSA(input,fltr,nh):\n",
        "    attn = []\n",
        "    print(\"Shape of CDSA Input\", input.shape)\n",
        "    feature_split = tf.split(input, num_or_size_splits= num_splits, axis=3)\n",
        "    print(feature_split[0].shape)\n",
        "    shape=K.int_shape(feature_split[0])\n",
        "    x = SSA(feature_split[0],fltr)\n",
        "    attn.append(x)\n",
        "    for i in range(1,nh):\n",
        "        x = Add()([feature_split[i],x])\n",
        "        x = SSA(x,fltr)\n",
        "        attn.append(x)\n",
        "    mh_lka_attn = Add()(attn)\n",
        "    mh_lka_attn = Conv2D(fltr,1, strides=1, padding='same', activation='relu')(mh_lka_attn)\n",
        "    print(\"Shape of CDSA Output\", mh_lka_attn.shape)\n",
        "    return mh_lka_attn\n"
      ],
      "metadata": {
        "id": "NVDzywSVfVX_",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CAL(input,fltr,nh):\n",
        "    print(\"Shape of CAL Input\", input.shape)\n",
        "    x = DefConv_full(input, fltr, kernel_size=3)\n",
        "    rs1 = x = Add()([x,input])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = CDSA(x,fltr,nh)\n",
        "    rs2 = x = Add()([rs1,x])\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = Conv2D(fltr, 1, padding='same', activation='relu')(x)\n",
        "    x = Add()([rs2,x])\n",
        "    print(\"Shape of CAL Output\", x.shape)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "PKnsju-la_cg",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fun= 'categorical_crossentropy'\n",
        "gpu_num=2\n",
        "k=5\n",
        "lr1=0.005\n",
        "lr2=0.0001\n",
        "image_size=224\n",
        "classes=8\n",
        "ratio=8\n",
        "fltr=256\n",
        "nh=4  # number of splits\n",
        "mag='40'"
      ],
      "metadata": {
        "id": "uQqoWozCTBhK",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
        "\n",
        "input_image = Input(shape=(224, 224, 3))\n",
        "mn_input = input_image\n",
        "\n",
        "# Load the model\n",
        "base_model = maxvit.MaxViT_Tiny(input_shape=(224, 224, 3), pretrained=\"imagenet\")\n",
        "new_base_model = Model(inputs=base_model.input, outputs=base_model.get_layer('stack_3_block_5/grid_ffn_output').output)\n",
        "mn_output = new_base_model(mn_input)\n",
        "print(mn_output.shape)\n",
        "\n",
        "mn_output = Conv2D(fltr, 1, padding='same', activation='relu')(mn_output)\n",
        "print(mn_output.shape)\n",
        "mn_output = BatchNormalization()(mn_output)  # Add Batch Normalization\n",
        "mn_output = Dropout(0.5)(mn_output)\n",
        "CAL_out = CAL(mn_output,fltr,nh)\n",
        "print(CAL_out.shape)\n",
        "CAL_out = GlobalAveragePooling2D()(CAL_out)\n",
        "out=Dense(classes,activation='softmax')(CAL_out)\n",
        "if gpu_num<1:\n",
        "    model=Model(inputs=input_image, outputs=out)\n",
        "    #model.summary()\n",
        "    parallel_model = multi_gpu_model(model, gpus=gpu_num)\n",
        "    parallel_model.summary()\n",
        "else:\n",
        "    parallel_model=Model(inputs=input_image, outputs=out)\n",
        "    parallel_model.summary()"
      ],
      "metadata": {
        "id": "i--5bFDwR9fx",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = train_model(parallel_model,train_gen,val_gen,test_gen,mag,image_size,'maxvit',lr1,lr2,4,100)"
      ],
      "metadata": {
        "id": "_6LvLQM-S6Vp",
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}